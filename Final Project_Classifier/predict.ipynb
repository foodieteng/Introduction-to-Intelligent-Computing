{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "from console_progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "def build_finetune_model(base_model, dropout, num_classes):\n",
    "\n",
    "    x = base_model.output \n",
    "\n",
    "    x = AveragePooling2D((5, 5), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax', name='finalfc')(x)\n",
    "    \n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 09:41:43.383800: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff102206430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HEIGHT = 299\n",
    "WIDTH = 299\n",
    "\n",
    "input_shape=(HEIGHT, WIDTH, 3)\n",
    "\n",
    "dropout = 0.7\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "model = build_finetune_model(base_model, dropout=dropout, num_classes=196)\n",
    "\n",
    "model.load_weights('keras_swa.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_data(fnames, bboxes):\n",
    "    src_folder = 'classifier_evaluation'\n",
    "    dst_folder = ''\n",
    "    num_samples = len(fnames)\n",
    "\n",
    "    pb = ProgressBar(total=100, prefix='Save test data', suffix='', decimals=3, length=50, fill='=')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        fname = fnames[i]\n",
    "        (x1, y1, x2, y2) = bboxes[i]\n",
    "        src_path = src_folder + str(fname)\n",
    "        src_image = cv.imread(src_path)\n",
    "        height, width = src_image.shape[:2]\n",
    "        # margins of 16 pixels\n",
    "        margin = 16\n",
    "        x1 = max(0, x1 - margin)\n",
    "        y1 = max(0, y1 - margin)\n",
    "        x2 = min(x2 + margin, width)\n",
    "        y2 = min(y2 + margin, height)\n",
    "        # print(fname)\n",
    "        pb.print_progress_bar((i + 1) * 100 / num_samples)\n",
    "\n",
    "        dst_path = os.path.join(dst_folder, fname)\n",
    "        crop_image = src_image[y1:y2, x1:x2]\n",
    "        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n",
    "        cv.imwrite(dst_path, dst_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8041/8041 [00:00<00:00, 713423.84it/s]\n",
      "  0%|          | 0/8041 [00:00<?, ?it/s]2022-01-05 09:42:30.723815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "100%|██████████| 8041/8041 [51:16<00:00,  2.61it/s]     \n"
     ]
    }
   ],
   "source": [
    "all_preds, file = [], []\n",
    "\n",
    "tmp = []\n",
    "for filename in tqdm(os.listdir('cars_test')):\n",
    "    tmp += [filename]\n",
    "\n",
    "tmp.sort()\n",
    "num_samples =len(tmp)\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    filename = os.path.join('cars_test',tmp[i])\n",
    "    bgr_img = cv.imread(filename)\n",
    "    rgb_img = cv.resize(cv.cvtColor(bgr_img, cv.COLOR_BGR2RGB)/255,(299,299))\n",
    "    rgb_img = np.expand_dims(rgb_img, 0)\n",
    "    preds = model.predict(rgb_img)\n",
    "    class_id = np.argmax(preds)\n",
    "    all_preds.append(class_id+1)\n",
    "    file += [tmp[i]]\n",
    "\n",
    "\n",
    " \n",
    "result = {'filename' : file,\n",
    "          'pred_label' : all_preds}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       filename  pred_label\n",
      "0     00001.jpg         181\n",
      "1     00002.jpg          93\n",
      "2     00003.jpg         145\n",
      "3     00004.jpg         187\n",
      "4     00005.jpg         185\n",
      "...         ...         ...\n",
      "8036  08037.jpg          63\n",
      "8037  08038.jpg          16\n",
      "8038  08039.jpg          16\n",
      "8039  08040.jpg          38\n",
      "8040  08041.jpg          32\n",
      "\n",
      "[8041 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sio.loadmat('devkit/cars_test_annos_withlabels.mat')\n",
    "actual_label = np.array(labels['annotations']['class'],dtype=np.int)\n",
    "actual_label = actual_label.squeeze()\n",
    "all_preds = np.array(all_preds)\n",
    "actual_label = actual_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8883223479666709\n"
     ]
    }
   ],
   "source": [
    "count = np.sum(actual_label == all_preds)\n",
    "print('accuracy = ', count/len(actual_label))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
